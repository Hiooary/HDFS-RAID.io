{
  "name": "Hdfs-raid.io",
  "tagline": "",
  "body": "原网址[https://wiki.apache.org/hadoop/HDFS-RAID](https://wiki.apache.org/hadoop/HDFS-RAID)\r\n由于英文的是在读起来有点吃力，所以结合百度翻译了一下。仅供自己参考分析。\r\n\r\n# HDFS RAID\r\n\r\n## 概述\r\n\r\nHDFS RAID模块提供了一个 Distributedraidfilesystem（DRFS）是随着 Hadoop Distributedfilesystem实例（DFS）使用的，存储在DRFS文件（源文件）中。被分为几个块组成的条纹。对于每个条带，多个奇偶校验块存储在对应于该源文件的奇偶校验文件中。这使得它有可能重新计算块的源文件或校验文件当丢失或损坏时。DRFS的主要好处是增加保护防止数据损坏。由于这种增加的保护，复制水平可以降低，同时保持相同的可用性保证，这会导致显着的存储空间的节省。\r\n\r\n## 体系结构与实现 \r\n\r\nHDFS RAID包含多个软件组件：\r\n  * DRFS客户端，它提供在 DRFS 的文件中访问应用程序并且透明地恢复在阅读文件时遇到的任何损坏或丢失块，\r\n  * RaidNode，一个存储在 DRFS 上的守护进程，为所有数据文件创建和维护校验文件，\r\n  * BlockFixer，定期重新计算已丢失或损坏的块，\r\n  * RaidShell 实用工具，它允许管理员手动触发重新计算丢失或损坏的块和检查已成为不可逆转损坏的文件，\r\n  * ErasureCode，它提供了编码和解码的字节块\r\n\r\n## DRFS客户端\r\n\r\nDRFS客户端上的DFS客户端拦截所有来电一层实现并把它们传给潜在的客户。当底层的DFS抛出一个checksumexception或blockmissingexception（因为他源文件包含损坏或丢失块），DRFS客户端捕获这些异常，找出当前源文件的校验文件并重新计算丢失块后返回给应用程序。\r\n需要注意的是，虽然DRFS客户端重新丢失块阅读损坏的文件没有插入这些丢失的块返回到文件系统时，重要的。相反，它摒弃他们，一旦应用程序请求已经完成。的blockfixer守护进程和raidshell工具可用于持续修复坏块。\r\n\r\n## RaidNode\r\n\r\nRaidNode定期扫描所有路径的配置指定要存储在装置。对于每一个路径，它递归检查所有的文件，有超过2个块，并选择那些没有最近修改过的（默认是在过去的24小时内）。一旦选择了一个源文件，遍历所有的条纹和创建适当的校验块的数目每个条纹。奇偶校验块然后被连接在一起，并存储为对应于该源文件的奇偶校验文件。一旦创建了奇偶校验文件，则将相应的源文件的复制因子降低为在配置中指定的副本。RaidNode还定期删除已成为孤儿或过时的校验文件。\r\n\r\n目前有两种实现RaidNode：\r\n* LocalRaidnode，在RaidNode局部计算奇偶校验块。由于计算奇偶校验块是一个计算昂贵的任务，这种方法的可扩展性是有限的。\r\n* DistributedRaidNode，调度图减少任务来计算奇偶校验块。\r\n\r\n## BlockFixer\r\n\r\nBlockFixer是一个在RaidNode运行的守护进程,并定期检查DRFS配置的健康路径。当一个块文件丢失或损坏时，这些模块被重计算并插回到文件系统。\r\n\r\nBlockFixer有两种实现：\r\n* LocalBlockFixer，在RaidNode局部重新计算坏块。\r\n* DistBlockFixer，调度图减少工作来重新计算块。\r\n\r\n## RaidShell\r\n\r\nRaidShell是一个允许系统管理员维护和检查DRFS的工具。它支持手动触发重新计算坏数据块的命令，并允许管理员显示不可恢复文件的列表（即文件的数据太多或校验块已丢失）。为了验证文件系统的完整性，运行RaidFSCK如下：\r\n   $HADOOP_HOME/bin/hadoop org.apache.hadoop.raid.RaidShell -fsck [path]\r\n这将打印一个损坏的文件列表（即，文件丢失了太多的块，不能再被固定的磁盘阵列）。 \r\n\r\n\r\nErasureCode\r\n\r\n（目前正在开发中）\r\n\r\nErasureCode是底层的组件，被BlockFixer和RaiNode用来生成校验块和固定奇偶校验/源块。ErasureCode编码并解码\r\n\r\n。编码时，ErasureCode需要几个源字节而且产生校验字节。解码时，ErasureCode通过查看剩余的源字节和校验字节\r\n\r\n产生丢失的字节（可作为校验或源字节）。\r\n\r\n丢失的字节数可以恢复，等于创建的奇偶校验字节数。例如，如果我们将10个源字节编码为3个奇偶校验字节。我们可\r\n\r\n以由其他10个剩余的字节恢复任何3个丢失的字节。\r\n\r\n在Raid里有两种纠删码的实现：XOR(异或)码和Reed-Solomon(里德所罗门)码。它们之间的区别是，XOR只允许创建一\r\n\r\n个校验字节但Reed Solomon码允许创建任何校验字节数。因此，当使用Reed Solomon而不丢失数据的安全时，在源文\r\n\r\n件上的复制可以减少到1。只有一个块的一个副本的缺点是，读取一个块必须去一个单一的机器，减少并行。因此，\r\n\r\nReed-Solomon应该使用的是不经常使用的数据。\r\n\r\n使用HDFS RAID\r\n\r\n安装\r\n\r\n整个代码封装在一个名为 hadoop-*-raid.jar 的单独的jar文件中。为了使用HDFS RAID，你需要把上面提到的jar文\r\n\r\n件引进到Hadoop的路径。最简单的实现方法是从 $HADOOP_HOME/build/contrib/raid 复制 hadoop * -raid.jar 到 \r\n\r\n$HADOOP_HOME/lib。或者你可以修改 $HADOOP_CLASSPATH（定义在 conf/hadoop-env.sh ）包括jar文件进来。\r\n\r\n配置\r\n\r\n有一个单独的配置文件 raid.xml，描述RAID应该使用的HDFS路径。这提供了一个需要进行突击检查的目录/文件模式\r\n\r\n列表。有相当多的选项可以为每个模式指定。这一文件的样本可以在 src/contrib/raid/conf/raid.xml 中找到。为\r\n\r\n了应用定义在 raid.xml 中的策略， 参考已被添加到 hdfs-site.xml：\r\n\r\n  <property>\r\n    <name>raid.config.file</name>\r\n    <value>/mnt/hdfs/DFS/conf/raid.xml</value>\r\n    <description>This is needed by the RaidNode </description>\r\n  </property>\r\n\r\n为了让客户使用DRFS客户端（DRFS透明地修复坏块），添加以下配置属性的到 hdfs-site.xml：\r\n  <property>\r\n    <name>fs.hdfs.impl</name>\r\n    <value>org.apache.hadoop.dfs.DistributedRaidFileSystem</value>\r\n    <description>The FileSystem for hdfs: uris.</description>\r\n  </property>\r\n\r\n附加（可选）配置\r\n\r\n下面的属性设置在 hdfs-site.xml 来进一步调整DRFS配置：\r\n\r\n指定要存储奇偶校验文件的位置：\r\n  <property>\r\n      <name>hdfs.raid.locations</name>\r\n      <value>hdfs://newdfs.data:8000/raid</value>\r\n      <description>The location for parity files. If this is\r\n        is not defined, then defaults to /raid.\r\n      </description>\r\n   </property>\r\n指定块中的奇偶校验条长度：\r\n<property>\r\n    <name>hdfs.raid.stripeLength</name>\r\n    <value>10</value>\r\n    <description>The number of blocks in a file to be combined into\r\n      a single raid parity block. The default value is 5. The lower\r\n      the number the greater is the disk space you will save when you\r\n      enable raid.\r\n    </description>\r\n  </property>\r\n指定HAR(硬件)部分文件的大小：\r\n  <property>\r\n    <name>raid.har.partfile.size</name>\r\n    <value>4294967296</value>\r\n    <description>The size of HAR part files that store raid parity\r\n      files. The default is 4GB. The higher the number the fewer the\r\n      number of files used to store the HAR archive.\r\n    </description>\r\n  </property>\r\n指定raid(磁盘阵列)的块放置策略： \r\n  <property>\r\n    <name>dfs.block.replicator.classname</name>\r\n    <value>\r\n      org.apache.hadoop.hdfs.server.namenode.BlockPlacementPolicyRaid\r\n    </value>\r\n    <description>The name of the class which specifies how to place\r\n      blocks in HDFS. The class BlockPlacementPolicyRaid will try to\r\n      avoid co-located replicas of the same stripe. This will greatly\r\n      reduce the probability of raid file corruption.\r\n    </descrition>\r\n  </property>\r\n指定应该用来运行由DistributedBlockFixer派出的工作的公平调度器池：\r\n<property>\r\n    <name>raid.mapred.fairscheduler.pool</name>\r\n    <value>none</value>\r\n    <description>The name of the fair scheduler pool to use.</description>\r\n  </property>\r\n指定要使用的RaidNode的实现（本地或分布式）： \r\n<property>\r\n    <name>raid.classname</name>\r\n    <value>org.apache.hadoop.raid.DistRaidNode</value>\r\n    <description>Specify which implementation of RaidNode to use\r\n      (class name).\r\n    </description>\r\n  </property>\r\n指定RaidNode重新计算过时或失踪的奇偶校验块的频率： \r\n <property>\r\n    <name>raid.policy.rescan.interval</name>\r\n    <value>5000</value>\r\n    <description>Specify the periodicity in milliseconds after which\r\n      all source paths are rescanned and parity blocks recomputed if\r\n      necessary. By default, this value is 1 hour.\r\n    </description>\r\n  </property>\r\n\r\n默认情况下，DRFS假设底层的文件系统是一个DFS。对于一些在其他的文件系统层的装置，定义一个指定基础类的名称\r\n\r\n的属性，命名为fs.raid.underlyingfs.impl。例如，对层DRFS在NewFileSystem的一个实例，使用以下属性：\r\n<property>\r\n    <name>fs.raid.underlyingfs.impl</name>\r\n    <value>org.apache.hadoop.new.NewFileSystem</value>\r\n    <description>Specify the filesystem that is layered immediately below the\r\n      DistributedRaidFileSystem. By default, this value is DistributedFileSystem.\r\n    </description>\r\n  </property\r\n指定要使用的BlockFixer实现（默认是DistBlockFixer）： \r\n <property>\r\n    <name>raid.blockfix.classname</name>\r\n    <value>org.apache.hadoop.raid.LocalBlockFixer</value>\r\n    <description>Specify the BlockFixer implementation to use.\r\n      The default is org.apache.hadoop.raid.DistBlockFixer.\r\n    </description>\r\n  </property>\r\n\r\n运行装置\r\n\r\nDRFS在运行时提供不停机的群集服务支持管理。这可能添加/删除新的路径进行突击检查，而不中断任何负载的集群。\r\n\r\nraid.xml的改变被定期检测（每隔几秒钟）并且新政策立即应用。\r\n\r\n在你的集群指定一个机器运行RaidNode软件。你可以在任何机器上运行这个守护进程而不管是否这个机器在运行其他\r\n\r\n的Hadoop守护进程。你可以开始在选定的机器上运行以下RaidNode：\r\n   nohup $HADOOP_HOME/bin/hadoop org.apache.hadoop.raid.RaidNode >> /xxx/logs/hadoop-root-raidnode-\r\n\r\nhadoop.xxx.com.log &\r\n\r\n我们还提供了两种更容易的脚本来启动和停止RaidNode。复制脚本start-raidnode.sh和stop-raidnode.sh到布置了\r\n\r\nRaidNode的机器的 $HADOOP_HOME/bin 目录下。然后你可以通过直接调用这些脚本开始或停止机器上的RaidNode。为\r\n\r\n了远程部署RaidNode，复制start-raidnode-remote.sh 和 stop-raidnode-remote.sh 到你想要触发远程部署的 \r\n\r\n$HADOOP_HOME/bin 下，并在包含RaidNode部署的机器名称的同一台机器上创建一个文本文件 \r\n\r\n$HADOOP_HOME/conf/raidnode。这些脚本ssh到指定的机器而且调用start-raidnode.sh/stop-raidnode.sh。\r\n\r\n为了易于维护，你可能想在JobTracker机器上改变start-mapred.sh，来自动调用start-raidnode-remote.sh（对\r\n\r\ntostop-mapred.sh 制造类似的变化去请求 stop-raidnode-remote.sh )\r\n\r\n为了监测一个DRFS健康，利用RaidShell提供的fsck命令。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}